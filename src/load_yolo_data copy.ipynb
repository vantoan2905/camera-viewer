{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1518a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA available: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Check CUDA\n",
    "print(\"Torch CUDA available:\", torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "688e368e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0.611502, 0.534624, 0.15493, 0.078638], [0, 0.602113, 0.671362, 0.178404, 0.161972]]\n"
     ]
    }
   ],
   "source": [
    "def get_labels( label_path):\n",
    "    labels = []\n",
    "    with open(label_path, 'r') as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 5:\n",
    "                class_id, cx, cy, w, h = map(float, parts)\n",
    "                labels.append([int(class_id), cx, cy, w, h])\n",
    "    return labels\n",
    "\n",
    "path = r\"D:\\object_detect_tracking\\data\\brain_tumor_copy\\axial_t1wce_2_class\\labels\\test\\00018_109.txt\"\n",
    "labels = get_labels(path)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509bcd28",
   "metadata": {},
   "source": [
    "# ---------------------- Dataset ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efbf2a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class YoloDataset(Dataset):\n",
    "    def __init__(self, data_dir, img_size=320, transform=None, mode='train', split_ratio_test=0.8):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "        self.split_ratio_test = split_ratio_test\n",
    "\n",
    "        self.train_df = []\n",
    "        self.val_df = []\n",
    "        self.test_df = []\n",
    "\n",
    "        self._filter_and_clean(data_dir)\n",
    "        self._prepare_dataset()\n",
    "\n",
    "    def _clean_images_without_labels(self, images_path, labels_path):\n",
    "        label_files = set(os.listdir(labels_path))\n",
    "        for img_file in os.listdir(images_path):\n",
    "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                label_name = os.path.splitext(img_file)[0] + '.txt'\n",
    "                if label_name not in label_files:\n",
    "                    os.remove(os.path.join(images_path, img_file))\n",
    "\n",
    "    def _clean_labels_without_images(self, labels_path, images_path):\n",
    "        image_files = set(os.listdir(images_path))\n",
    "        for label_file in os.listdir(labels_path):\n",
    "            if label_file.endswith('.txt'):\n",
    "                img_name = os.path.splitext(label_file)[0]\n",
    "                found = any(\n",
    "                    (img_name + ext) in image_files\n",
    "                    for ext in ['.jpg', '.jpeg', '.png']\n",
    "                )\n",
    "                if not found:\n",
    "                    os.remove(os.path.join(labels_path, label_file))\n",
    "\n",
    "    def _filter_and_clean(self, dir_path):\n",
    "        for folder_name in os.listdir(dir_path):\n",
    "            folder_path = os.path.join(dir_path, folder_name)\n",
    "            if not os.path.isdir(folder_path):\n",
    "                continue\n",
    "\n",
    "            if \"images\" in folder_name:\n",
    "                for subset in os.listdir(folder_path):\n",
    "                    images_path = os.path.join(folder_path, subset)\n",
    "                    labels_path = os.path.join(dir_path, folder_name.replace('images', 'labels'), subset)\n",
    "                    if os.path.exists(labels_path):\n",
    "                        self._clean_images_without_labels(images_path, labels_path)\n",
    "\n",
    "            elif \"labels\" in folder_name:\n",
    "                for subset in os.listdir(folder_path):\n",
    "                    labels_path = os.path.join(folder_path, subset)\n",
    "                    images_path = os.path.join(dir_path, folder_name.replace('labels', 'images'), subset)\n",
    "                    if os.path.exists(images_path):\n",
    "                        self._clean_labels_without_images(labels_path, images_path)\n",
    "\n",
    "    def _transform_image(self, image_path):\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "    def _get_labels(self, label_path):\n",
    "        labels = []\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) == 5:\n",
    "                    class_id, cx, cy, w, h = map(float, parts)\n",
    "                    labels.append([int(class_id), cx, cy, w, h])\n",
    "        return labels\n",
    "\n",
    "    def _prepare_dataset(self):\n",
    "        image_base = os.path.join(self.data_dir, 'images')\n",
    "        label_base = os.path.join(self.data_dir, 'labels')\n",
    "\n",
    "        for subset in ['train', 'test']:\n",
    "            img_folder = os.path.join(image_base, subset)\n",
    "            lbl_folder = os.path.join(label_base, subset)\n",
    "\n",
    "            image_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "            if subset == 'test':\n",
    "                val_len = int(len(image_files) * self.split_ratio_test)\n",
    "                val_files = image_files[:val_len]\n",
    "                test_files = image_files[val_len:]\n",
    "            else:\n",
    "                val_files, test_files = [], []\n",
    "\n",
    "            for img_file in image_files:\n",
    "                img_path = os.path.join(img_folder, img_file)\n",
    "                lbl_path = os.path.join(lbl_folder, os.path.splitext(img_file)[0] + '.txt')\n",
    "                if not os.path.exists(lbl_path):\n",
    "                    continue\n",
    "                img = self._transform_image(img_path)\n",
    "                lbl = self._get_labels(lbl_path)\n",
    "\n",
    "                if subset == 'train':\n",
    "                    self.train_df.append((img, lbl))\n",
    "                elif subset == 'test':\n",
    "                    if img_file in val_files:\n",
    "                        self.val_df.append((img, lbl))\n",
    "                    else:\n",
    "                        self.test_df.append((img, lbl))\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode == 'train':\n",
    "            return len(self.train_df)\n",
    "        elif self.mode == 'val':\n",
    "            return len(self.val_df)\n",
    "        elif self.mode == 'test':\n",
    "            return len(self.test_df)\n",
    "        return 0\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.mode == 'train':\n",
    "            return self.train_df[idx]\n",
    "        elif self.mode == 'val':\n",
    "            return self.val_df[idx]\n",
    "        elif self.mode == 'test':\n",
    "            return self.test_df[idx]\n",
    "\n",
    "    def get_df(self):\n",
    "        return self.train_df, self.val_df, self.test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c726f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transform and DataLoader setup\n",
    "transform = T.Compose([\n",
    "    T.Resize((320, 320)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "data_dir = r\"D:/object_detect_tracking/data/brain_tumor_copy/axial_t1wce_2_class\"\n",
    "load_yolo_data  = YoloDataset(data_dir, transform, split_ratio_test=0.2)\n",
    "train_df , val_df, test_df = load_yolo_data.get_df()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18d0d529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 15 60\n",
      "[[0, 0.428991, 0.361502, 0.144366, 0.150235]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(train_df), len(val_df), len(test_df))\n",
    "image , label = train_df[0]\n",
    "print (label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fafcd2",
   "metadata": {},
   "source": [
    "# ---------------------- SIoU Loss --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4be2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SIoU(nn.Module):\n",
    "    def __init__(self, eps=1e-7):\n",
    "        super(SIoU, self).__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, box1, box2):\n",
    "        # box1, box2: [N, 4] or [4]\n",
    "        # YOLO normalized: [cx, cy, w, h]\n",
    "        if box1.ndim == 1:\n",
    "            box1 = box1.unsqueeze(0)\n",
    "        if box2.ndim == 1:\n",
    "            box2 = box2.unsqueeze(0)\n",
    "\n",
    "        b1_x1 = box1[:, 0] - box1[:, 2] / 2\n",
    "        b1_y1 = box1[:, 1] - box1[:, 3] / 2\n",
    "        b1_x2 = box1[:, 0] + box1[:, 2] / 2\n",
    "        b1_y2 = box1[:, 1] + box1[:, 3] / 2\n",
    "\n",
    "        b2_x1 = box2[:, 0] - box2[:, 2] / 2\n",
    "        b2_y1 = box2[:, 1] - box2[:, 3] / 2\n",
    "        b2_x2 = box2[:, 0] + box2[:, 2] / 2\n",
    "        b2_y2 = box2[:, 1] + box2[:, 3] / 2\n",
    "\n",
    "        inter_w = (torch.min(b1_x2, b2_x2) - torch.max(b1_x1, b2_x1)).clamp(0)\n",
    "        inter_h = (torch.min(b1_y2, b2_y2) - torch.max(b1_y1, b2_y1)).clamp(0)\n",
    "        inter = inter_w * inter_h\n",
    "\n",
    "        w1 = b1_x2 - b1_x1 + self.eps\n",
    "        h1 = b1_y2 - b1_y1 + self.eps\n",
    "        w2 = b2_x2 - b2_x1 + self.eps\n",
    "        h2 = b2_y2 - b2_y1 + self.eps\n",
    "\n",
    "        union = w1 * h1 + w2 * h2 - inter + self.eps\n",
    "        iou = inter / union\n",
    "\n",
    "        cw = torch.max(b1_x2, b2_x2) - torch.min(b1_x1, b2_x1) + self.eps\n",
    "        ch = torch.max(b1_y2, b2_y2) - torch.min(b1_y1, b2_y1) + self.eps\n",
    "        s_cw = (b2_x1 + b2_x2 - b1_x1 - b1_x2) * 0.5\n",
    "        s_ch = (b2_y1 + b2_y2 - b1_y1 - b1_y2) * 0.5\n",
    "        sigma = torch.sqrt(s_cw ** 2 + s_ch ** 2) + self.eps\n",
    "\n",
    "        sin_alpha_1 = torch.abs(s_cw) / sigma\n",
    "        sin_alpha_2 = torch.abs(s_ch) / sigma\n",
    "        threshold = torch.sqrt(torch.tensor(2.0)) / 2\n",
    "        sin_alpha = torch.where(sin_alpha_1 > threshold, sin_alpha_2, sin_alpha_1)\n",
    "\n",
    "        angle_cost = 1 - 2 * torch.pow(torch.sin(torch.arcsin(sin_alpha) - torch.pi / 4), 2)\n",
    "        rho_x = (s_cw / cw) ** 2\n",
    "        rho_y = (s_ch / ch) ** 2\n",
    "        gamma = 2 - angle_cost\n",
    "        distance_cost = 2 - torch.exp(-gamma * rho_x) - torch.exp(-gamma * rho_y)\n",
    "\n",
    "        omiga_w = torch.abs(w1 - w2) / torch.max(w1, w2)\n",
    "        omiga_h = torch.abs(h1 - h2) / torch.max(h1, h2)\n",
    "        shape_cost = torch.pow(1 - torch.exp(-omiga_w), 4) + torch.pow(1 - torch.exp(-omiga_h), 4)\n",
    "\n",
    "        siou = iou - 0.5 * (distance_cost + shape_cost)\n",
    "\n",
    "        return 1 - siou.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8efaeb",
   "metadata": {},
   "source": [
    "# Example SIoU loss usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f1e493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3173433542251587\n"
     ]
    }
   ],
   "source": [
    "siou = SIoU()\n",
    "\n",
    "# Example (YOLO normalized):\n",
    "# box1 = [cx, cy, w, h]\n",
    "# box2 = [cx, cy, w, h]\n",
    "box1 = torch.tensor([0.5, 0.5, 0.2, 0.2])\n",
    "box2 = torch.tensor([0.52, 0.52, 0.22, 0.22])\n",
    "\n",
    "loss = siou(box1, box2)\n",
    "print(loss.item())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd58d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b53cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model.yolo.yolo_net import YOLONet\n",
    "\n",
    "# SIoU loss implementation\n",
    "class SIoU(nn.Module):\n",
    "    def __init__(self, eps=1e-7):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, box1: torch.Tensor, box2 : torch.Tensor)-> float:\n",
    "        if box1.ndim == 1:\n",
    "            box1 = box1.unsqueeze(0)\n",
    "        if box2.ndim == 1:\n",
    "            box2 = box2.unsqueeze(0)\n",
    "\n",
    "        b1_x1 = box1[:, 0] - box1[:, 2] / 2\n",
    "        b1_y1 = box1[:, 1] - box1[:, 3] / 2\n",
    "        b1_x2 = box1[:, 0] + box1[:, 2] / 2\n",
    "        b1_y2 = box1[:, 1] + box1[:, 3] / 2\n",
    "\n",
    "        b2_x1 = box2[:, 0] - box2[:, 2] / 2\n",
    "        b2_y1 = box2[:, 1] - box2[:, 3] / 2\n",
    "        b2_x2 = box2[:, 0] + box2[:, 2] / 2\n",
    "        b2_y2 = box2[:, 1] + box2[:, 3] / 2\n",
    "\n",
    "        inter_w = (torch.min(b1_x2, b2_x2) - torch.max(b1_x1, b2_x1)).clamp(0)\n",
    "        inter_h = (torch.min(b1_y2, b2_y2) - torch.max(b1_y1, b2_y1)).clamp(0)\n",
    "        inter = inter_w * inter_h\n",
    "\n",
    "        w1 = b1_x2 - b1_x1 + self.eps\n",
    "        h1 = b1_y2 - b1_y1 + self.eps\n",
    "        w2 = b2_x2 - b2_x1 + self.eps\n",
    "        h2 = b2_y2 - b2_y1 + self.eps\n",
    "\n",
    "        union = w1 * h1 + w2 * h2 - inter + self.eps\n",
    "        iou = inter / union\n",
    "\n",
    "        cw = torch.max(b1_x2, b2_x2) - torch.min(b1_x1, b2_x1) + self.eps\n",
    "        ch = torch.max(b1_y2, b2_y2) - torch.min(b1_y1, b2_y1) + self.eps\n",
    "        s_cw = (b2_x1 + b2_x2 - b1_x1 - b1_x2) * 0.5\n",
    "        s_ch = (b2_y1 + b2_y2 - b1_y1 - b1_y2) * 0.5\n",
    "        sigma = torch.sqrt(s_cw ** 2 + s_ch ** 2) + self.eps\n",
    "\n",
    "        sin_alpha_1 = torch.abs(s_cw) / sigma\n",
    "        sin_alpha_2 = torch.abs(s_ch) / sigma\n",
    "        threshold = torch.sqrt(torch.tensor(2.0)) / 2\n",
    "        sin_alpha = torch.where(sin_alpha_1 > threshold, sin_alpha_2, sin_alpha_1)\n",
    "\n",
    "        angle_cost = 1 - 2 * torch.pow(torch.sin(torch.arcsin(sin_alpha) - torch.pi / 4), 2)\n",
    "        rho_x = (s_cw / cw) ** 2\n",
    "        rho_y = (s_ch / ch) ** 2\n",
    "        gamma = 2 - angle_cost\n",
    "        distance_cost = 2 - torch.exp(-gamma * rho_x) - torch.exp(-gamma * rho_y)\n",
    "\n",
    "        omiga_w = torch.abs(w1 - w2) / torch.max(w1, w2)\n",
    "        omiga_h = torch.abs(h1 - h2) / torch.max(h1, h2)\n",
    "        shape_cost = torch.pow(1 - torch.exp(-omiga_w), 4) + torch.pow(1 - torch.exp(-omiga_h), 4)\n",
    "\n",
    "        siou = iou - 0.5 * (distance_cost + shape_cost)\n",
    "        return 1 - siou.mean()\n",
    "\n",
    "# Process YOLO output\n",
    "def process_output(output: torch.Tensor, num_anchors=3, num_classes=2)-> torch.Tensor:\n",
    "    B, C, S, _ = output.shape\n",
    "    output = output.permute(0, 2, 3, 1).contiguous()\n",
    "    output = output.view(B, S, S, num_anchors, 5 + num_classes)\n",
    "    return output\n",
    "\n",
    "# YOLO + SIoU loss\n",
    "def calculate_loss(output: torch.Tensor, target: list)-> float:\n",
    "    siou_loss = SIoU()\n",
    "    total_loss = 0\n",
    "    count = 0\n",
    "    for b in range(output.shape[0]):\n",
    "        for i in range(output.shape[1]):\n",
    "            for j in range(output.shape[2]):\n",
    "                for a in range(output.shape[3]):\n",
    "                    pred = output[b, i, j, a, :4]\n",
    "                    # type of target is list\n",
    "                    for target_bbox in target:\n",
    "                        target_bbox = torch.tensor(target_bbox).to(device)\n",
    "                        loss = siou_loss(pred, target_bbox)\n",
    "                        total_loss += loss\n",
    "                    count += 1\n",
    "    return total_loss / count\n",
    "\n",
    "# Training loop\n",
    "model = YOLONet(num_classes=2, num_anchors=3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_anchors = 3\n",
    "num_classes = 2\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for images, targets in train_df:\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out_13, out_26, out_52 = model(images)\n",
    "        out_13_proc = process_output(out_13, num_anchors, num_classes)\n",
    "        out_26_proc = process_output(out_26, num_anchors, num_classes)\n",
    "        out_52_proc = process_output(out_52, num_anchors, num_classes)\n",
    "\n",
    "        loss13 = calculate_loss(out_13_proc, targets)\n",
    "        loss26 = calculate_loss(out_26_proc, targets)\n",
    "        loss52 = calculate_loss(out_52_proc, targets)\n",
    "\n",
    "        mean_loss = (loss13 + loss26 + loss52) / 3\n",
    "\n",
    "        mean_loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += mean_loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{epochs}] Loss: {total_loss / len(train_df):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42744f1",
   "metadata": {},
   "source": [
    "# ---------------------- Training model ----------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e97be328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3734)\n"
     ]
    }
   ],
   "source": [
    "output = torch.rand(1, 2, 2, 1, 4)\n",
    "\n",
    "target = [\n",
    "    [0.5, 0.5, 0.2, 0.2],\n",
    "    [0.52, 0.52, 0.22, 0.22]\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "siou_loss = SIoU()\n",
    "siou_loss = SIoU()\n",
    "total_loss = 0\n",
    "count = 0\n",
    "for b in range(output.shape[0]):\n",
    "    for i in range(output.shape[1]):\n",
    "        for j in range(output.shape[2]):\n",
    "            for a in range(output.shape[3]):\n",
    "                pred = output[b, i, j, a, :4]\n",
    "                # type of target is list\n",
    "                for target_bbox in target:\n",
    "                    target_bbox = torch.tensor(target_bbox)\n",
    "                    loss = siou_loss(pred, target_bbox)\n",
    "                    total_loss += loss\n",
    "                count += 1\n",
    "print( total_loss / count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cb3be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
